{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Requirement already satisfied: jedi==0.17.2 in c:\\conda\\envs\\ds\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\conda\\envs\\ds\\lib\\site-packages (from jedi==0.17.2) (0.7.1)\n"
     ]
    }
   ],
   "source": [
    "%cd -q D:\\data\\progr\\audio_widener\\pycharm_proj\n",
    "%load_ext autoreload\n",
    "!pip install jedi==0.17.2\n",
    "%autoreload 2\n",
    "from imports import *\n",
    "\n",
    "sound1, sound2 = guitar_wd1, guitar_wd2\n",
    "\n",
    "# sound = jazz_sample\n",
    "# sound = ghostbusters_sample\n",
    "sound = guitar_sample\n",
    "# sound1, sound2 = electro_sample, electro_sample\n",
    "# sound1 = sound2 = np.sin(np.linspace(0, 3000, sample_rate) * 20) + np.sin(np.linspace(0, 3000, sample_rate) * 8)\n",
    "\n",
    "# corellation, coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sound, rate=sample_rate, autoplay=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio([sound1, sound2], rate=guitar_sample_rate, autoplay=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sxx, drawing_params = create_spectrogram(sound1, sample_rate, \"angle\")\n",
    "Sxx2, drawing_params = create_spectrogram(sound1, sample_rate, \"magnitude\")\n",
    "\n",
    "fig, Sxx = create_spectrogram_figure(Sxx, drawing_params, title=\"Phase\", colorscale=\"HSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.imshow(np.real(phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 33, 3):\n",
    "    f = create_spectrogram(sound1, sample_rate, \"complex\")[0][i]\n",
    "    x = np.real(f)\n",
    "    y = np.imag(f)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(y)))\n",
    "\n",
    "    cs = [colors[i * len(x)//len(x)] for i in range(len(x))]\n",
    "    plt.scatter(x, y, color=cs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66423666 0.07334227\n",
      "Dash app running on http://127.0.0.1:8092/\n",
      "0.7611754017257353 0.07361490659261624\n",
      "0.7991434421468266 0.0737749304975519\n",
      "0.710039521972035 0.07364755153708076\n",
      "0.7418513827366866 0.07406374299918148\n",
      "0.7193863929579004 0.07409232428610314\n",
      "0.7289971390826232 0.07540836578472652\n",
      "0.7814978184434535 0.07386424800399247\n",
      "1.064629861084005 0.0777450553314523\n",
      "sound has too big value\n",
      "0.9248753742088673 0.07480775111975332\n",
      "0.9819944698358746 0.07670539190257955\n"
     ]
    }
   ],
   "source": [
    "from imports import *\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import base64\n",
    "\n",
    "def sound_to_html(sound, sample_rate): \n",
    "    sound = np.array(sound).transpose()\n",
    "    print(np.max(np.abs(sound)), np.mean(np.abs(sound)))\n",
    "    if np.max(np.abs(sound)) > 1:\n",
    "        print(\"sound has too big value\")\n",
    "        sound /= np.max(np.abs(sound))\n",
    "        \n",
    "    stream = io.BytesIO()\n",
    "    wavfile.write(stream, sample_rate, (sound * 32766).astype(np.int16))\n",
    "\n",
    "    return \"data:audio/wav;base64,\" + base64.b64encode(stream.read()).decode(\"ascii\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "# code and plot setup\n",
    "# settings\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "def create_dash_app(data, sound, sample_rate, mmethods):\n",
    "#     sound1, sound2, mask = mmethods[0][0](sound, sample_rate)\n",
    "    sound1 = sound2 = sound\n",
    "    data = create_figures(sound, sound, sound, sample_rate) + data\n",
    "    \n",
    "    figs = [i[0] for i in data]\n",
    "    graphs = []\n",
    "    for i, fig in enumerate(figs):\n",
    "        graphs.append(dcc.Graph(id='graph' + str(i), figure=fig))\n",
    "        \n",
    "    layouts = [\n",
    "        html.Div([\"Current method: \",\n",
    "                     html.Div([\"0\"], id=\"current_method\")\n",
    "                 ]),\n",
    "        dcc.Checklist(\n",
    "            id=\"checklist_options\",\n",
    "            options=[\n",
    "                {'label': 'norm values per row', 'value': 'need_norm_per_row_values'},\n",
    "                {'label': 'log scale values', 'value': 'need_log_scale_values'},\n",
    "                {'label': 'log scale freqs', 'value': 'need_log_scale_frequency'},\n",
    "                {'label': 'filter low values', 'value': 'need_filter_low_values'}\n",
    "            ],\n",
    "            value=['need_norm_per_row_values', 'need_log_scale_values']\n",
    "        ) ,\n",
    "        html.Div([\n",
    "            \"log scale coef:\",\n",
    "            dcc.Slider(\n",
    "                id='log_scale_coeff',\n",
    "                min=50,\n",
    "                max=1000,\n",
    "                step=0.5,\n",
    "                value=100\n",
    "            ),\n",
    "        ], style={'width': '300px', 'display': 'inline-block'}),\n",
    "        html.Div(graphs),\n",
    "        html.Div([\n",
    "            html.H4(\"Original sound: \"), \n",
    "              html.Audio([\n",
    "                html.Source(src=sound_to_html(sound, sample_rate))\n",
    "            ], controls=\"controls\")\n",
    "        ]),\n",
    "        html.Div([html.H2(\"Methods testing\")]), \n",
    "    ]\n",
    "    \n",
    "    \n",
    "    methods = [{\"id\" : \"method\" + str(i), \"callable_method\" : callable_method, \n",
    "                \"create_layout\": create_layout, \"create_callback_inputs\" : create_callback_inputs} \\\n",
    "                for (i, (callable_method, create_layout, create_callback_inputs)) in enumerate(mmethods)]\n",
    "    for method in methods:\n",
    "        id = method[\"id\"]\n",
    "        layouts.append(html.Div([\n",
    "            html.H2(id),\n",
    "            html.Div(method[\"create_layout\"](id)),\n",
    "            html.H4(\"Stereo: \"),\n",
    "            html.Div(\n",
    "                [\"loading...\"],\n",
    "                id=\"stereo_audio\" + id\n",
    "            ),\n",
    "            html.Div([\"loading\"], id=\"layout_addition\" + id),\n",
    "            html.Div(\"0\", id='last_time_used' + id, style={'display': 'none'})\n",
    "        ]))\n",
    "    \n",
    "    app = JupyterDash(__name__)\n",
    "    app.layout = html.Div(layouts)\n",
    "    \n",
    "    cur_time = 0\n",
    "    for i, method in enumerate(methods):\n",
    "        @app.callback([Output('stereo_audio' + method[\"id\"], 'children'),\n",
    "                       Output('layout_addition' + method[\"id\"], 'children'),\n",
    "                       Output('last_time_used' + method[\"id\"], \"children\")],\n",
    "                       method[\"create_callback_inputs\"](method[\"id\"]))\n",
    "        def run_method(*args):\n",
    "            nonlocal cur_time, sound1, sound2\n",
    "            sound1, sound2, layout_addition = method[\"callable_method\"](sound, sample_rate, *args)\n",
    "            cur_time += 1\n",
    "            return html.Audio([html.Source(src=sound_to_html((sound1, sound2), sample_rate))],  \\\n",
    "                                  controls=\"controls\", id=str(cur_time)), \\\n",
    "                              layout_addition, \\\n",
    "                              str(cur_time)\n",
    "    \n",
    "    last_called_method = 0\n",
    "    need_recreate_figs = False\n",
    "    \n",
    "    @app.callback([Output('current_method', 'children')],\n",
    "                 [Input('last_time_used'+  method[\"id\"], 'children') for method in methods])\n",
    "    def sync_methods(*times):\n",
    "        nonlocal last_called_method, last_called_method, need_recreate_figs\n",
    "        for i, time in enumerate(times):\n",
    "            if cur_time == int(time):\n",
    "                need_recreate_figs = True\n",
    "                last_called_method = i\n",
    "                return [str(last_called_method)]\n",
    "                  \n",
    "        raise Exception(\"wtf \" + str(cur_time) + \": \" + str(times))\n",
    "    \n",
    "    @app.callback(\n",
    "        [Output('graph' + str(i), 'figure') for i in range(len(figs))] ,\n",
    "        [Input('current_method', 'children'),\n",
    "         Input('checklist_options', \"value\"),\n",
    "         Input('log_scale_coeff', \"value\")]\n",
    "    )\n",
    "    def streamFig(_, checklist_options, log_scale_coeff):\n",
    "        nonlocal need_recreate_figs, data\n",
    "        if need_recreate_figs:\n",
    "            ddata = create_figures(sound, sound1, sound2, sample_rate)\n",
    "            data[:len(ddata)] = ddata\n",
    "            figs[:len(ddata)] = [i[0] for i in data[:len(ddata)]]\n",
    "            need_recreate_figs = False\n",
    "            \n",
    "        \n",
    "        for (fig, Sxx, apply_params_func) in data:\n",
    "            apply_params_func(checklist_options, log_scale_coeff)\n",
    "\n",
    "        return figs\n",
    "\n",
    "    app.run_server(mode='external', port=8092, dev_tools_ui=True, #debug=True,\n",
    "                  dev_tools_hot_reload=True, threaded=True)\n",
    "\n",
    "    \n",
    "def create_figures(sound, sound1, sound2, sample_rate):\n",
    "    fig1 = create_magnitude_figure(sound1, sample_rate)\n",
    "    fig2 = create_magnitude_figure(sound2, sample_rate)\n",
    "    return [fig1, fig2]\n",
    "    \n",
    "\n",
    "\n",
    "# mm = create_spectrogram_figure(mask, {\"t\": t, \"freqs\" : f}, \"mask\") + (lambda a, b: b,)\n",
    "# fig2 = create_phase_figure(sound1, sample_rate)\n",
    "create_dash_app([], sound, sample_rate, [create_dashed_method_with_mask()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def test_mask(func):\n",
    "    global mask, t, Zxx, f\n",
    "    nperseg = 1024\n",
    "    noverlap = 512\n",
    "\n",
    "    f, t, Zxx = signal.stft(sound, sample_rate, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "    mask = func(Zxx)\n",
    "\n",
    "\n",
    "    # mask[:,0]\n",
    "    # mask[0, :]\n",
    "\n",
    "    plt.imshow(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = split_into_bands_by_parts(is_dynamic=True)\n",
    "test_mask(mask_generator)\n",
    "sound1, sound2 = m2s_freq_split(sound, sample_rate, mask_generator)\n",
    "audio_mono_stereo(sound, sound1, sound2, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = split_into_bands_log(is_dynamic=False)\n",
    "test_mask(mask_generator)\n",
    "sound1, sound2 = m2s_freq_split(sound, sample_rate, 10, mask_generator )\n",
    "audio_mono_stereo(sound, sound1, sound2, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# weights = np.array([[0, 0, 1, 0, 0],\n",
    "#                     [0, 2, 4, 2, 0],\n",
    "#                     [1, 4, 8, 4, 1],\n",
    "#                     [0, 2, 4, 2, 0],\n",
    "#                     [0, 0, 1, 0, 0]],\n",
    "#                    dtype=np.float)\n",
    "# weights = weights / np.sum(weights[:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfilters.convolve(mask, weights, mode='constant').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound1, sound2 = m2s_freq_split(sound, sample_rate, 10, split_into_bands_static)\n",
    "audio_mono_stereo(sound, sound1, sound2, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Zxx * mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(create_spectrogram(guitar_wd1, sample_rate, \"phase\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(plt.specgram(guitar_wd1, mode=\"phase\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(Sxx, NFFT, noverlap, Fs, freqs, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter, fourier_uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound1, sound2 = m2s_freq_split(sound, sample_rate, 10, split_into_bands_static)\n",
    "audio_mono_stereo(sound, sound1, sound2, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = guitar_sample\n",
    "\n",
    "nperseg = 1024\n",
    "noverlap = 512\n",
    "\n",
    "f, t, Zxx = signal.stft(song, sample_rate, nperseg=nperseg, noverlap=noverlap)\n",
    "# mask = split_into_bands(Zxx, 50)\n",
    "\n",
    "mask = np.zeros_like(Zxx, dtype=\"float\")\n",
    "cnt = 0\n",
    "g = 0\n",
    "for i in range(len(mask)):\n",
    "    if cnt == 25:\n",
    "        cnt = 0\n",
    "        g += 1\n",
    "        \n",
    "    mask[i, :] = g     \n",
    "    cnt += 1\n",
    "\n",
    "borders = []\n",
    "last = 0\n",
    "lastpos = -1\n",
    "\n",
    "for i in range(len(mask)):\n",
    "    if mask[i][0] != last:\n",
    "        borders.append((lastpos + 1, i))\n",
    "        last = mask[i][0]\n",
    "        lastpos = i\n",
    "\n",
    "mask1 = np.ones_like(mask)\n",
    "\n",
    "for (left, right) in borders:\n",
    "    mid = (left + right) // 2\n",
    "    val = 0\n",
    "    for j in range(left, mid + 1):\n",
    "        mask1[j] *= val\n",
    "#         print(val)\n",
    "        val += 1 / (mid + 1 - left)\n",
    "\n",
    "    for j in range(mid + 1, right  + 1):\n",
    "        mask1[j] *= val\n",
    "#         print(val)\n",
    "        val -= 1 / (right - mid)\n",
    "        \n",
    "#     break\n",
    "        \n",
    "mask2 = np.ones_like(mask1) - mask1\n",
    "    \n",
    "# mask1 = mask % 2 == 0\n",
    "# mask2 = mask % 2 == 1\n",
    "\n",
    "# Zxx1[mask1] = 0\n",
    "# Zxx2[mask2] = 0\n",
    "#     #     for i in range(Zxx.shape[0]):\n",
    "\n",
    "#     #         if i % 15 < 9:\n",
    "#     #             Zxx1[i,:] = 0\n",
    "#     #         else:\n",
    "#     #             Zxx2[i,:] = 0\n",
    "# _, sound1 = signal.istft(Zxx1, sample_rate, nperseg=nperseg, noverlap=noverlap)\n",
    "# _, sound2 = signal.istft(Zxx2, sample_rate, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "# return sound1, sound2\n",
    "\n",
    "Zxx1 = Zxx * mask1\n",
    "Zxx2 = Zxx * mask2\n",
    "\n",
    "_, sound1 = signal.istft(Zxx1, sample_rate, nperseg=nperseg, noverlap=noverlap)\n",
    "_, sound2 = signal.istft(Zxx2, sample_rate, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "\n",
    "print(\"stereo:\")\n",
    "display(Audio([sound1, sound2], rate=guitar_sample_rate, autoplay=True, normalize=True))\n",
    "print(\"mono:\")\n",
    "display(Audio(song, rate=sample_rate, autoplay=False, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(guitar_sample - sound1[:len(guitar_sample)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_spec_image(Sxx, extent, vmin, vmax, log_scale=False):\n",
    "    cmap = plt.cm.get_cmap(\"bwr\")\n",
    "    plt.imshow(Sxx, extent=extent, cmap=cmap, origin=\"upper\", vmin=vmin, vmax=vmax)\n",
    "    plt.gca().axis('auto')\n",
    "    if log_scale:\n",
    "        plt.yscale(\"log\", base=10)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().minorticks_off()\n",
    "    ticks = [100, 1000, 2000, 5000, 10000]\n",
    "    plt.yticks(ticks, map(str, ticks))\n",
    "    plt.ylim(50, 11000)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_spectrogram(Sxx, NFFT, noverlap, Fs, freqs, t):\n",
    "    %matplotlib widget\n",
    "    Sxx = np.flipud(Sxx)\n",
    "    max_per_row = np.max(np.abs(Sxx), axis=-1)[:, None]\n",
    "    Sxx = np.divide(Sxx, max_per_row, out=np.zeros_like(Sxx), where=max_per_row!=0)\n",
    "    Sxx /= np.max(Sxx)\n",
    "    \n",
    "    vmax = max(np.max(Sxx), np.min(Sxx))\n",
    "    vmin = -vmax\n",
    "    \n",
    "    pad_xextent = (NFFT-noverlap) / Fs / 2\n",
    "    xmin, xmax = np.min(t) - pad_xextent, np.max(t) + pad_xextent\n",
    "    extent = xmin, xmax, freqs[0], freqs[-1]\n",
    "    \n",
    "    if vmin == vmax:\n",
    "        vmin, vmax = -1, 1\n",
    "    \n",
    "    plot_spec_image(Sxx, extent, vmin, vmax)\n",
    "    red_patch = mpatches.Patch(color='red', label='Left')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Right')\n",
    "    plt.legend(handles=[red_patch, blue_patch])\n",
    "    \n",
    "\n",
    "    \n",
    "def visualize_stereo(sound1, sound2, sample_rate, cut=1):\n",
    "    %matplotlib widget\n",
    "    if cut:\n",
    "        sound1 = sound1[:sample_rate * cut]\n",
    "        sound2 = sound2[:sample_rate * cut]\n",
    "    spec1, drawing_params = create_spectrogram(sound1, sample_rate)\n",
    "    spec2, drawing_params = create_spectrogram(sound2, sample_rate)\n",
    "    spec1 = np.log10(spec1 * 100 +1)\n",
    "    spec2 = np.log10(spec2 * 100 + 1)\n",
    "#     print(np.max(spec1 - spec2))\n",
    "#     print(np.max(spec1))\n",
    "    plot_spectrogram(spec1 - spec2, **drawing_params)\n",
    "    \n",
    "def vizualize_phase(sound1, sound2, sample_rate, cut=1):\n",
    "    %matplotlib widget\n",
    "    if cut:\n",
    "        sound1 = sound1[:sample_rate * cut]\n",
    "        sound2 = sound2[:sample_rate * cut]\n",
    "    spec1, drawing_params = create_spectrogram(sound1, sample_rate)\n",
    "    spec2, drawing_params = create_spectrogram(sound2, sample_rate)\n",
    "    plot_spectrogram(spec1, **drawing_params)\n",
    "    plot_spectrogram(spec2, **drawing_params)\n",
    "#     plot_spectrogram(np.abs(spec1-spec2), **drawing_params) \n",
    "    \n",
    "    \n",
    "# умножить разность в фазе на амплитуду, чтобы занулить бесполезные частоты\n",
    "visualize_stereo(sound1, sound2, jazz_sample_rate, cut=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
